{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#import os\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pymongo import MongoClient\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "import json\n",
    "import csv\n",
    "\n",
    "from apscheduler.schedulers.blocking import BlockingScheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connecting to MongoDB\n",
    "client = MongoClient('mongo', 27017, username='admin', password='DataMan2019!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From csv to json on MongoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_to_json(csvFilePath, jsonFilePath):\n",
    "    jsonArray = []\n",
    "      \n",
    "    #read csv file\n",
    "    with open(csvFilePath, encoding='utf-8') as csvf: \n",
    "        #load csv file data using csv library's dictionary reader\n",
    "        csvReader = csv.DictReader(csvf) \n",
    "\n",
    "        #convert each csv row into python dict\n",
    "        for row in csvReader: \n",
    "            #add this python dict to json array\n",
    "            jsonArray.append(row)\n",
    "  \n",
    "    #convert python jsonArray to JSON String and write to file\n",
    "    with open(jsonFilePath, 'w', encoding='utf-8') as jsonf: \n",
    "        jsonString = json.dumps(jsonArray, indent=4)\n",
    "        jsonf.write(jsonString)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from csv to json\n",
    "csvFilePath = 'df_sino.csv'\n",
    "jsonFilePath = 'df_sino.json'\n",
    "csv_to_json(csvFilePath, jsonFilePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('df_sino.json') as f:\n",
    "  data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pymongo.results.InsertManyResult at 0x7f2cec893dc8>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#from json to mongodb\n",
    "client.stockex.sino.insert_many(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>data</th>\n",
       "      <th>location</th>\n",
       "      <th>id</th>\n",
       "      <th>testo</th>\n",
       "      <th>username</th>\n",
       "      <th>replyCount</th>\n",
       "      <th>like</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>quoteCount</th>\n",
       "      <th>...</th>\n",
       "      <th>lang</th>\n",
       "      <th>url</th>\n",
       "      <th>coordinates</th>\n",
       "      <th>place</th>\n",
       "      <th>followersCount</th>\n",
       "      <th>friendsCount</th>\n",
       "      <th>statusesCount</th>\n",
       "      <th>favouritesCount</th>\n",
       "      <th>listedCount</th>\n",
       "      <th>mediaCount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>60b2463b10d9bb0d1938e933</td>\n",
       "      <td>2021-05-24 23:56:36+00:00</td>\n",
       "      <td>Toronto, Canada</td>\n",
       "      <td>1.396978e+18</td>\n",
       "      <td>@themojoguy @benwedge @EmmMacfarlane Especiall...</td>\n",
       "      <td>TheTradeLawGuy</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>en</td>\n",
       "      <td>https://twitter.com/TheTradeLawGuy/status/1396...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>358.0</td>\n",
       "      <td>358.0</td>\n",
       "      <td>4803.0</td>\n",
       "      <td>4602.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>217.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>60b2463b10d9bb0d1938e934</td>\n",
       "      <td>2021-05-24 23:53:37+00:00</td>\n",
       "      <td>Toronto, Canada</td>\n",
       "      <td>1.396978e+18</td>\n",
       "      <td>@themojoguy @benwedge @EmmMacfarlane That can'...</td>\n",
       "      <td>TheTradeLawGuy</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>en</td>\n",
       "      <td>https://twitter.com/TheTradeLawGuy/status/1396...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>358.0</td>\n",
       "      <td>358.0</td>\n",
       "      <td>4803.0</td>\n",
       "      <td>4602.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>217.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>60b2463b10d9bb0d1938e935</td>\n",
       "      <td>2021-05-24 23:50:46+00:00</td>\n",
       "      <td>Goderich, Ontario</td>\n",
       "      <td>1.396977e+18</td>\n",
       "      <td>@sunlorrie BS fear mongering article “As an ex...</td>\n",
       "      <td>summeki</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>en</td>\n",
       "      <td>https://twitter.com/summeki/status/13969770006...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>172.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>5005.0</td>\n",
       "      <td>1163.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>134.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>60b2463b10d9bb0d1938e936</td>\n",
       "      <td>2021-05-24 23:47:57+00:00</td>\n",
       "      <td>Australia</td>\n",
       "      <td>1.396976e+18</td>\n",
       "      <td>@Virg2101 @ROO3sixty @Mooby_Doo @JohnRuddick2 ...</td>\n",
       "      <td>Christo69933840</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>en</td>\n",
       "      <td>https://twitter.com/Christo69933840/status/139...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>83.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>27460.0</td>\n",
       "      <td>8460.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8454.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>60b2463b10d9bb0d1938e937</td>\n",
       "      <td>2021-05-24 23:43:51+00:00</td>\n",
       "      <td>Australia</td>\n",
       "      <td>1.396975e+18</td>\n",
       "      <td>@ROO3sixty @Virg2101 @Mooby_Doo @JohnRuddick2 ...</td>\n",
       "      <td>Christo69933840</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>en</td>\n",
       "      <td>https://twitter.com/Christo69933840/status/139...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>83.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>27460.0</td>\n",
       "      <td>8460.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8454.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        _id                       data           location  \\\n",
       "0  60b2463b10d9bb0d1938e933  2021-05-24 23:56:36+00:00    Toronto, Canada   \n",
       "1  60b2463b10d9bb0d1938e934  2021-05-24 23:53:37+00:00    Toronto, Canada   \n",
       "2  60b2463b10d9bb0d1938e935  2021-05-24 23:50:46+00:00  Goderich, Ontario   \n",
       "3  60b2463b10d9bb0d1938e936  2021-05-24 23:47:57+00:00          Australia   \n",
       "4  60b2463b10d9bb0d1938e937  2021-05-24 23:43:51+00:00          Australia   \n",
       "\n",
       "             id                                              testo  \\\n",
       "0  1.396978e+18  @themojoguy @benwedge @EmmMacfarlane Especiall...   \n",
       "1  1.396978e+18  @themojoguy @benwedge @EmmMacfarlane That can'...   \n",
       "2  1.396977e+18  @sunlorrie BS fear mongering article “As an ex...   \n",
       "3  1.396976e+18  @Virg2101 @ROO3sixty @Mooby_Doo @JohnRuddick2 ...   \n",
       "4  1.396975e+18  @ROO3sixty @Virg2101 @Mooby_Doo @JohnRuddick2 ...   \n",
       "\n",
       "          username  replyCount  like  retweet_count  quoteCount  ...  lang  \\\n",
       "0   TheTradeLawGuy         1.0   0.0            0.0         0.0  ...    en   \n",
       "1   TheTradeLawGuy         1.0   0.0            0.0         0.0  ...    en   \n",
       "2          summeki         0.0   1.0            1.0         0.0  ...    en   \n",
       "3  Christo69933840         0.0   0.0            0.0         0.0  ...    en   \n",
       "4  Christo69933840         0.0   0.0            0.0         0.0  ...    en   \n",
       "\n",
       "                                                 url coordinates place  \\\n",
       "0  https://twitter.com/TheTradeLawGuy/status/1396...                     \n",
       "1  https://twitter.com/TheTradeLawGuy/status/1396...                     \n",
       "2  https://twitter.com/summeki/status/13969770006...                     \n",
       "3  https://twitter.com/Christo69933840/status/139...                     \n",
       "4  https://twitter.com/Christo69933840/status/139...                     \n",
       "\n",
       "  followersCount friendsCount  statusesCount  favouritesCount  listedCount  \\\n",
       "0          358.0        358.0         4803.0           4602.0          6.0   \n",
       "1          358.0        358.0         4803.0           4602.0          6.0   \n",
       "2          172.0        172.0         5005.0           1163.0          2.0   \n",
       "3           83.0         83.0        27460.0           8460.0          5.0   \n",
       "4           83.0         83.0        27460.0           8460.0          5.0   \n",
       "\n",
       "   mediaCount  \n",
       "0       217.0  \n",
       "1       217.0  \n",
       "2       134.0  \n",
       "3      8454.0  \n",
       "4      8454.0  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sino_tweet = list(client.twitter.sino.find({}))\n",
    "sino_tweet_df = pd.DataFrame(sino_tweet, dtype = float)\n",
    "sino_tweet_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>Datetime</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>60b2466110d9bb0d19395178</td>\n",
       "      <td>2021-04-08 09:30:00+08:00</td>\n",
       "      <td>19.200001</td>\n",
       "      <td>19.379999</td>\n",
       "      <td>19.040001</td>\n",
       "      <td>19.299999</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>60b2466110d9bb0d19395179</td>\n",
       "      <td>2021-04-08 09:31:00+08:00</td>\n",
       "      <td>19.219999</td>\n",
       "      <td>19.340000</td>\n",
       "      <td>19.219999</td>\n",
       "      <td>19.340000</td>\n",
       "      <td>56000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>60b2466110d9bb0d1939517a</td>\n",
       "      <td>2021-04-08 09:32:00+08:00</td>\n",
       "      <td>19.320000</td>\n",
       "      <td>19.480000</td>\n",
       "      <td>19.320000</td>\n",
       "      <td>19.440001</td>\n",
       "      <td>70400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>60b2466110d9bb0d1939517b</td>\n",
       "      <td>2021-04-08 09:33:00+08:00</td>\n",
       "      <td>19.420000</td>\n",
       "      <td>19.459999</td>\n",
       "      <td>19.360001</td>\n",
       "      <td>19.420000</td>\n",
       "      <td>43200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>60b2466110d9bb0d1939517c</td>\n",
       "      <td>2021-04-08 09:34:00+08:00</td>\n",
       "      <td>19.480000</td>\n",
       "      <td>19.500000</td>\n",
       "      <td>19.320000</td>\n",
       "      <td>19.459999</td>\n",
       "      <td>74000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        _id                   Datetime       Open       High  \\\n",
       "0  60b2466110d9bb0d19395178  2021-04-08 09:30:00+08:00  19.200001  19.379999   \n",
       "1  60b2466110d9bb0d19395179  2021-04-08 09:31:00+08:00  19.219999  19.340000   \n",
       "2  60b2466110d9bb0d1939517a  2021-04-08 09:32:00+08:00  19.320000  19.480000   \n",
       "3  60b2466110d9bb0d1939517b  2021-04-08 09:33:00+08:00  19.420000  19.459999   \n",
       "4  60b2466110d9bb0d1939517c  2021-04-08 09:34:00+08:00  19.480000  19.500000   \n",
       "\n",
       "         Low      Close   Volume  \n",
       "0  19.040001  19.299999      0.0  \n",
       "1  19.219999  19.340000  56000.0  \n",
       "2  19.320000  19.440001  70400.0  \n",
       "3  19.360001  19.420000  43200.0  \n",
       "4  19.320000  19.459999  74000.0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sino_stockex = list(client.stockex.sino.find({}))\n",
    "sino_stockex_df = pd.DataFrame(sino_stockex, dtype = float)\n",
    "sino_stockex_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def daily_integration(tweet_df, stockex_df, hours):\n",
    "    # Type datetime and timezone\n",
    "    \n",
    "    tweet_df['data'] = pd.to_datetime(tweet_df['data'])\n",
    "    \n",
    "    stockex_df['Datetime'] = pd.to_datetime(stockex_df['Datetime'])\n",
    "    stockex_df['Datetime']=stockex_df['Datetime'].dt.tz_localize(None)\n",
    "\n",
    "    # Time delta for (-8 for timezone +1 for correlation)\n",
    "    hours_added = datetime.timedelta(hours = hours)\n",
    "    stockex_df['Datetime']= stockex_df['Datetime'] + hours_added\n",
    "    \n",
    "    hours = 24 - hours   #+24\n",
    "    hours_added = datetime.timedelta(hours = hours)\n",
    "    tweet_df['data']= tweet_df['data'] + hours_added\n",
    "\n",
    "    # Type datetime and timezone\n",
    "    tweet_df['data'] = pd.to_datetime(tweet_df['data'])\n",
    "    tweet_df['data']=tweet_df['data'].dt.tz_localize(None)\n",
    "\n",
    "    # Rename\n",
    "    tweet_df = tweet_df.rename(columns={'data': 'Datetime'})\n",
    "\n",
    "    # Sort\n",
    "    tweet_df = tweet_df.sort_values(by=\"Datetime\")\n",
    "\n",
    "    # Delete hour and minutes\n",
    "    tweet_df['date'] = pd.to_datetime(tweet_df['Datetime']).dt.date\n",
    "    \n",
    "    # Create column for number of day (0 is Sunday, 6 is Saturday)\n",
    "    tweet_df['day_of_week'] = tweet_df['Datetime'].dt.strftime('%w')\n",
    "    \n",
    "    # Add a day on for every Sunday\n",
    "    hours=+24\n",
    "    hours_added = datetime.timedelta(hours = hours)\n",
    "\n",
    "    tweet_df['Datetime'] = np.where(tweet_df['day_of_week'] == '0',tweet_df['Datetime']+hours_added,tweet_df['Datetime'])\n",
    "\n",
    "    # Add two day on for every Saturday\n",
    "    hours=+48\n",
    "    hours_added = datetime.timedelta(hours = hours)\n",
    "    tweet_df['Datetime'] = np.where(tweet_df['day_of_week'] == '6',tweet_df['Datetime']+hours_added,tweet_df['Datetime'])\n",
    "\n",
    "    # Sunday on Monday\n",
    "    tweet_df[tweet_df['day_of_week']=='0']\n",
    "    \n",
    "    # Saturday on Monday\n",
    "    tweet_df[tweet_df['day_of_week']=='6']\n",
    "    \n",
    "    #sentiment\n",
    "    analyzer = SentimentIntensityAnalyzer()\n",
    "    df =[]\n",
    "    for sentence in tweet_df['testo']:\n",
    "        vs = analyzer.polarity_scores(sentence)\n",
    "        vs_df = pd.DataFrame.from_dict(vs.values(), orient='columns')\n",
    "        df.append(vs_df[0][3])\n",
    "    tweet_df['compound'] = df\n",
    "    tweet_df['compound'].describe()\n",
    "    \n",
    "    # Rewrite date for weekend\n",
    "    tweet_df['date'] = pd.to_datetime(tweet_df['Datetime']).dt.date\n",
    "\n",
    "    #tweet daily analysis\n",
    "    company_count=pd.DataFrame(dtype=float)\n",
    "\n",
    "    # Count tweet by hour\n",
    "    company_count['N of Tweet']= tweet_df.groupby('date')['id'].count()\n",
    "\n",
    "    # Count like ecc by hour and divide by number of tweet\n",
    "    company_count['sum of Nlike']= tweet_df.groupby('date')['like'].sum()\n",
    "    company_count['median of Nlike']= tweet_df.groupby('date')['like'].median()\n",
    "    company_count['max of Nlike']= tweet_df.groupby('date')['like'].max()\n",
    "    company_count['sum of retweet']= tweet_df.groupby('date')['retweet_count'].sum()\n",
    "    company_count['median of retweet']= tweet_df.groupby('date')['retweet_count'].median()\n",
    "    company_count['max of retweet']= tweet_df.groupby('date')['retweet_count'].max()\n",
    "    company_count['sum of reply']= tweet_df.groupby('date')['replyCount'].sum()\n",
    "    company_count['median of reply']= tweet_df.groupby('date')['replyCount'].median()\n",
    "    company_count['max of reply']= tweet_df.groupby('date')['replyCount'].max()\n",
    "    company_count['Comp']= tweet_df.groupby('date')['compound'].sum()/company_count['N of Tweet']\n",
    "    \n",
    "    company_count.reset_index(inplace=True)\n",
    "    \n",
    "    company_count = company_count.rename(columns={'date': 'Datetime'})\n",
    "    \n",
    "    company_count['Datetime'] = pd.to_datetime(company_count['Datetime'])\n",
    "    company_count['day_of_week'] = company_count['Datetime'].dt.strftime('%w')\n",
    "    #company_count['Datetime'] = pd.to_datetime(company_count['Datetime']).dt.date\n",
    "    #company_count['Datetime'] = pd.to_datetime(company_count['Datetime'])\n",
    "    \n",
    "    company_count['N of Tweet'] = np.where(company_count['day_of_week'] == '1',company_count['N of Tweet']/3,company_count['N of Tweet'])\n",
    "    company_count['sum of Nlike'] = np.where(company_count['day_of_week'] == '1',company_count['sum of Nlike']/3,company_count['sum of Nlike'])\n",
    "    company_count['sum of retweet'] = np.where(company_count['day_of_week'] == '1',company_count['sum of retweet']/3,company_count['sum of retweet'])\n",
    "    company_count['sum of reply'] = np.where(company_count['day_of_week'] == '1',company_count['sum of reply']/3,company_count['sum of reply'])\n",
    "\n",
    "    #stock data\n",
    "    # Delete hour from stock dataset\n",
    "    stockex_df['Datetime'] = pd.to_datetime(stockex_df['Datetime']).dt.date\n",
    "    stockex_df = stockex_df.drop_duplicates(subset='Datetime', keep=\"last\")\n",
    "    stockex_df['Datetime'] = pd.to_datetime(stockex_df['Datetime'])\n",
    "    \n",
    "    # Merge stock data and tweet indices \n",
    "    df_int = stockex_df.merge(company_count, on='Datetime', how='left', indicator=False)\n",
    "    df_int.to_csv('int.csv')\n",
    "    csv_to_json('int.csv', 'int.json')\n",
    "    with open('int.json') as f:\n",
    "      data = json.load(f)\n",
    "    return df_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def job_daily_function(tweet_df, stockex_df, hours):\n",
    "    data = daily_integration(tweet_df, stockex_df, hours)\n",
    "    client.integrated_daily.sino.insert_many(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def job_func():\n",
    "    job_daily_function(sino_tweet_df, sino_stockex_df, -8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An exception occurred\n"
     ]
    }
   ],
   "source": [
    "# Scheduler\n",
    "sched = BlockingScheduler()\n",
    "\n",
    "try:\n",
    "    sched.add_job(job_func, 'cron', day_of_week='mon-fri', hour='10-3', minute=30)\n",
    "    sched.start()\n",
    "\n",
    "except:\n",
    "    print(\"An exception occurred\")\n",
    "    #pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
